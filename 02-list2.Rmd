# List 2: Bayesian Inference in Gaussian Models

## Bayesian inference in a simple Gaussian model

Let's start with a simple, one-dimensional Gaussian example, where

$$y_i |\mu, \sigma^2 \sim \mbox{N}(\mu,\sigma^2).$$

We will assume that $\mu$ and $\sigma$ are unknown, and will put conjugate priors on them both, so that

$$
\begin{aligned}
  \sigma^2 \sim& \mbox{Inv-Gamma}(\alpha_0, \beta_0)\\
  \mu|\sigma^2 \sim& \mbox{Normal}\left(\mu_0, \frac{\sigma^2}{\kappa_0}\right)\end{aligned}
$$

or, equivalently,
$$
\begin{aligned}
  y_i |\mu, \omega \sim& \mbox{N}(\mu,1/\omega)\\
  \omega \sim& \mbox{Gamma}(\alpha_0, \beta_0)\\
  \mu|\omega \sim& \mbox{Normal}\left(\mu_0, \frac{1}{\omega\kappa_0}\right)\end{aligned}
$$

We refer to this as a normal/inverse gamma prior on $\mu$ and $\sigma^2$ (or a normal/gamma prior on $\mu$ and $\omega$). We will now explore the posterior distributions on $\mu$ and $\omega$(/$\sigma^2$) -- much of this will involve similar results to those obtained in the first set of exercises.




```{exercise}
  Derive the conditional posterior distributions $p(\mu, \omega|y_1,\dots, y_n)$ (or $p(\mu, \sigma^2|y_1,\dots, y_n)$) and show that it is in the same family as $p(\mu, \omega)$. What are the updated parameters $\alpha_n, \beta_n,\mu_n$ and $\kappa_n$?
```

----

***Solution***. These computations are very similar to those in the previous list. So here is the summarised version using  of the direct computation with Bayes' rule
$$
\begin{aligned}
p(\mu, \omega \mid y) & \propto p(x\mid \mu, \omega ) p(\mu,\sigma) \\
& = p(y\mid \mu, \omega ) p(\mu \mid \omega)p(\omega) \\
& \propto \omega^{n/2}\exp\left\{ -\frac{\omega}{2} \sum_{i=1}^n(y_i - \mu)^2 \right\}
\exp\left\{ -\frac{\omega}{2\kappa_0} (\mu - \mu_0)^2 \right\} \omega^{\alpha_0-1}\exp\{-\beta_0 \omega\} \\
& \propto \omega^{n/2}\exp\left\{ -\frac{\omega}{2}\left(\sum_{i=1}^n(y_i - \bar{y})^2 + n(\bar{y} - \mu)^2 \right)\right\}
\exp\left\{ -\frac{\omega}{2\kappa_0} (\mu - \mu_0)^2 \right\} \omega^{\alpha_0-1}\exp\{-\beta_0 \omega\} \\

& \propto \omega^{n/2 + \alpha_0 - 1}\exp\left\{ -\frac{\omega}{2}\left((n + \omega / \kappa_0) \mu^2 - 2(n\bar{y} + \mu_0/\kappa_0) \mu + n\bar{y}^2 + \mu_0^2/\kappa_0   \right)\right\}
\exp\left\{ -\left( \beta_0  +  \frac{1}{2}\sum_{i=1}^n(y_i - \bar{y})^2 + \frac{1}{2\kappa_0}\mu_0^2 \right)\omega \right\} \\
&= \omega^{n/2 + \alpha_0 - 1}  \exp\left\{ -\frac{n\omega + \omega / \kappa_0}{2} \left(\mu - \frac{n \bar{y} + \mu_0/\kappa_0}{n + 1/\kappa_0}\right)^2 \right\}\exp\left\{ -\left( \beta_0  +  \frac{1}{2}\sum_{i=1}^n(y_i - \bar{y})^2 + \frac{1}{2\kappa_0}\mu_0^2 \right)\omega \right\}
\end{aligned} 
$$

----

```{exercise}
  Derive the conditional posterior distribution $p(\mu|\omega,y_1,\dots, y_n)$ and $p(\omega|y_1,\dots, y_n)$ (or if you'd prefer, $p(\mu|\sigma^2, y_1,\dots, y_n)$ and $p(\sigma^2|y_1,\dots, y_n)$). Based on this and the previous exercise, what are reasonable interpretations for the parameters $\mu_0,\kappa_0, \alpha_0$ and $\beta_0$?
```

----

***Solution***. 

----
